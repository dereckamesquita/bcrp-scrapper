# -*- coding: utf-8 -*-
"""BCRP - Scrapper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CFS6qirWxo-Puqn0vkJh23uv9BW5fV8O
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup
import warnings
warnings.filterwarnings("ignore")
import urllib.request

def scraperbcrp(direct):

  # URL de la página web a scrapear
  user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'
  url = direct
  headers={'User-Agent':user_agent,}
  request=urllib.request.Request(url,None,headers) #The assembled request
  try:
    response = urllib.request.urlopen(request)
  except:
    print('error',direct)
  data = response.read() # The data u need
  soup =  BeautifulSoup(data)
  # Obtenemos la tabla que contiene los datos
  tabla = soup.find("table", class_ = "series")

  # Obtenemos todas las filas de la tabla, excepto la primera que corresponde a los encabezados
  filas = tabla.find_all("tr")[1:]

  # Creamos una lista vacía para almacenar los datos
  datos = []

  # Recorremos las filas y obtenemos los datos de cada columna
  for fila in filas:
      celdas = fila.find_all("td")
      periodo = celdas[0].text.strip()
      valor = celdas[1].text.strip()
      datos.append((periodo, valor))


  #ultima_fila = df1.iloc[-1]
  # Obtener nombre de la serie
  nombre = soup.title.text
   # Convertimos la lista de datos en un DataFrame de Pandas
  df1 = pd.DataFrame(datos, columns=["Periodo", nombre])
  #Trasponer dataframe
  transposed_df = df1.transpose()
  transposed_df.columns = transposed_df.iloc[0]
  transposed_df = transposed_df[1:]
  #Cortar elementos
  index_to_drop = transposed_df.columns.get_loc('Ago22')

# Eliminar columnas desde la primera hasta 'Feb95'
  df = transposed_df.drop(transposed_df.columns[:index_to_drop], axis=1)

  return df
  #return nombre, ultima_fila

def bcrpscrapper(datos):
    """
    Scrapea datos del BCRP de forma libre.

    Parámetros:
        datos (str o list): Puede ser una lista "[]" o un string. Usa la o las URLS que te proporciona el BCRP

    Return:
        DataFrame con los

    Ejemplos:
    """
    if isinstance(datos, str): #Comprobando si es una lista o no
      datos = [datos]

    df_vacio = pd.DataFrame()
    y = 1
    tiempo = 0
    for x in datos:
      print(x)
      data = scraperbcrp(x)
      df_vacio = pd.concat([df_vacio, data])
      contar = y/len(datos)
      tiempo = tiempo + contar
      print(tiempo)

    return df_vacio
